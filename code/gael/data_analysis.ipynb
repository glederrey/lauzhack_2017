{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, date\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "data = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atms = pd.read_csv(data + 'atms.small.csv')\n",
    "clients = pd.read_csv(data + 'clients.small.csv')\n",
    "companies = pd.read_csv(data + 'companies.small.csv')\n",
    "transactions = pd.read_csv(data + 'transactions.small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = {}\n",
    "days = {}\n",
    "counts = 0\n",
    "dates = []\n",
    "for i in transactions.index:\n",
    "    date = transactions.loc[i]['date']\n",
    "    month = int(date.split('/')[1])\n",
    "    day = int(date.split('/')[0])\n",
    "    \n",
    "    if month not in months.keys():\n",
    "        months[month] = 0\n",
    "    \n",
    "    months[month] += 1\n",
    "    if day not in days.keys():\n",
    "        days[day] = 0\n",
    "    \n",
    "    days[day] += 1\n",
    "    \n",
    "    if day > 12 and month > 12:\n",
    "        counts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11905019472090005"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts/len(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 618,\n",
       " 2: 622,\n",
       " 3: 663,\n",
       " 4: 527,\n",
       " 5: 518,\n",
       " 6: 661,\n",
       " 7: 564,\n",
       " 8: 570,\n",
       " 9: 627,\n",
       " 10: 450,\n",
       " 11: 505,\n",
       " 12: 507,\n",
       " 13: 759,\n",
       " 14: 552,\n",
       " 15: 575,\n",
       " 16: 612,\n",
       " 17: 843,\n",
       " 18: 675,\n",
       " 19: 579,\n",
       " 20: 922,\n",
       " 21: 612,\n",
       " 22: 709,\n",
       " 23: 752,\n",
       " 24: 556,\n",
       " 25: 503,\n",
       " 26: 474,\n",
       " 27: 646,\n",
       " 28: 515,\n",
       " 29: 558,\n",
       " 30: 579,\n",
       " 31: 235}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1246,\n",
       " 2: 1301,\n",
       " 3: 1188,\n",
       " 4: 1265,\n",
       " 5: 1283,\n",
       " 6: 1368,\n",
       " 7: 1241,\n",
       " 8: 1317,\n",
       " 9: 1307,\n",
       " 10: 1270,\n",
       " 11: 1284,\n",
       " 12: 1542,\n",
       " 13: 49,\n",
       " 14: 52,\n",
       " 15: 43,\n",
       " 16: 49,\n",
       " 17: 46,\n",
       " 18: 40,\n",
       " 19: 45,\n",
       " 20: 45,\n",
       " 21: 37,\n",
       " 22: 44,\n",
       " 23: 41,\n",
       " 24: 233,\n",
       " 25: 524,\n",
       " 26: 573,\n",
       " 27: 1055}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract time and flow patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold_minutes = 15\n",
    "threshold_amount = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for source\n",
      "Check for target\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f929405649f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# Amount diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mamj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mamk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gayouf/Applications/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gayouf/Applications/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gayouf/Applications/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# for perf reasons we want to try _xs first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "groups = {'source': {'time': [], 'flow': []},\n",
    "          'target': {'time': [], 'flow': []}}\n",
    "\n",
    "ids = {'source': transactions['source'].unique(), 'target': transactions['target'].unique()}\n",
    "\n",
    "for key in ids.keys():\n",
    "    print('Check for {}'.format(key))\n",
    "    for id_ in ids[key]:\n",
    "        df = transactions[transactions[key] == id_]\n",
    "        df.index = range(len(df))\n",
    "\n",
    "        times = np.zeros((len(df), len(df)), dtype=np.bool)\n",
    "        amounts = np.zeros((len(df), len(df)), dtype=np.bool)\n",
    "\n",
    "\n",
    "        for j in range(len(df)):\n",
    "            for k in range(j, len(df)):\n",
    "                # Time diff\n",
    "                tj = datetime.strptime(df.loc[j]['time'], '%H:%M:%S').time()\n",
    "                tk = datetime.strptime(df.loc[k]['time'], '%H:%M:%S').time()\n",
    "\n",
    "                diff = np.abs(((datetime.combine(date.today(), tj) - datetime.combine(date.today(), tk)).total_seconds()))\n",
    "\n",
    "                if diff < threshold_minutes*60:\n",
    "                    times[j][k] = True\n",
    "                    times[k][j] = True\n",
    "                else:\n",
    "                    times[j][k] = False\n",
    "                    times[k][j] = False\n",
    "\n",
    "                # Amount diff\n",
    "\n",
    "                amj = df.loc[j]['amount']\n",
    "                amk = df.loc[k]['amount']\n",
    "\n",
    "                diff = np.abs(amj-amk)\n",
    "                avg = np.mean([amj, amk])\n",
    "\n",
    "                if diff < threshold_amount*avg:\n",
    "                    amounts[j][k] = True\n",
    "                    amounts[k][j] = True\n",
    "                else:\n",
    "                    amounts[j][k] = False\n",
    "                    amounts[k][j] = False\n",
    "\n",
    "        mat = amounts*times\n",
    "        \n",
    "        j=0\n",
    "        while j <= len(df)-1:\n",
    "            arr = [i for i, x in enumerate(mat[j, :]) if x]\n",
    "            j = arr[-1]+1\n",
    "            if len(arr) > 2:\n",
    "                linked = [df.loc[k]['id'] for k in arr]\n",
    "                if len(df[df['id'].isin(linked)]['date'].unique()) == 1:\n",
    "                    groups[key]['flow'].append(linked)\n",
    "                else:\n",
    "                    groups[key]['time'].append(linked) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in groups.keys():\n",
    "    print('{}:'.format(key))\n",
    "    for type_ in groups[key].keys():\n",
    "        print('  {}: {}'.format(type_, len(groups[key][type_])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(data + 'groups.json', 'w') as outfile:\n",
    "    json.dump(groups, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for similar transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(data + 'groups.json', 'r') as outfile:\n",
    "    groups = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in groups.keys():\n",
    "    for type_ in groups[key].keys():\n",
    "        \n",
    "        ids = []\n",
    "        dup = []\n",
    "        for i, g in enumerate(groups[key][type_]):\n",
    "            df = transactions[transactions['id'].isin(g)]\n",
    "            id_ = df[key].iloc[0]\n",
    "\n",
    "            if id_ in ids:\n",
    "                dup.append([ids.index(id_), i])\n",
    "            ids.append(id_)  \n",
    "            \n",
    "        merge = []\n",
    "        for pair in dup:\n",
    "            amount1 = np.mean(transactions[transactions['id'].isin(groups[key][type_][pair[0]])]['amount'])\n",
    "            amount2 = np.mean(transactions[transactions['id'].isin(groups[key][type_][pair[1]])]['amount'])\n",
    "\n",
    "            delta = np.abs(amount1-amount2)\n",
    "\n",
    "            if delta < threshold_amount*np.mean([amount1, amount2]):\n",
    "                merge.append(pair)\n",
    "                \n",
    "        to_del = []\n",
    "        for pair in merge:\n",
    "            groups[key][type_][pair[0]] = list(np.append(groups[key][type_][pair[0]], groups[key][type_][pair[1]]))\n",
    "\n",
    "            to_del.append(pair[1])\n",
    "            \n",
    "        for index in sorted(to_del, reverse=True):\n",
    "            del groups[key][type_][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in groups.keys():\n",
    "    print('{}:'.format(key))\n",
    "    for type_ in groups[key].keys():\n",
    "        print('  {}: {}'.format(type_, len(groups[key][type_])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data + 'groups.json', 'w') as outfile:\n",
    "    json.dump(groups, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract JSON for d3js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-335897830881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'groups.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msource_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gayouf/Applications/anaconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gayouf/Applications/anaconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gayouf/Applications/anaconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gayouf/Applications/anaconda3/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "with open(data + 'groups.json', 'r') as outfile:\n",
    "    groups = json.load(outfile)\n",
    "    \n",
    "source_ids = []\n",
    "for g in groups['source']['time']:\n",
    "    susp_node = transactions[transactions['id'].isin(g)]['source'].iloc[0]\n",
    "    source_ids.append(susp_node)\n",
    "    \n",
    "target_ids = []\n",
    "for g in groups['target']['time']:\n",
    "    susp_node = transactions[transactions['id'].isin(g)]['source'].iloc[0]\n",
    "    target_ids.append(susp_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group 0 = suspect\n",
    "# group 1 = accomplice\n",
    "# group 2 = accomplice edge\n",
    "# group 3 = normal\n",
    "# group 4 = normal edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'nodes': [], 'links': [], 'type': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "susp_node = transactions[transactions['id'].isin(groups['source']['time'][id_])]['source'].iloc[0]\n",
    "data['nodes'].append({'id': susp_node, 'tag': 'suspect', 'type': 'suspect'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "susp_index = list(transactions[transactions['id'].isin(groups['source']['time'][id_])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = transactions[transactions['source'] == susp_node]\n",
    "\n",
    "for i in out.index:\n",
    "    row = out.loc[i]\n",
    "    acc = True if i in susp_index else False\n",
    "    if acc:\n",
    "        tag = 'accomplice'\n",
    "    else:\n",
    "        tag = 'usual'\n",
    "    \n",
    "    if row['target'] not in link_nums.keys():\n",
    "        data['nodes'].append({'id': row['target'], 'tag': tag, 'type': 'target'})\n",
    "        \n",
    "    data['links'].append({'source': susp_node, 'target': row['target'], 'tag': tag, 'date': row['date'], 'time': row['time'], 'amount': row['amount'], 'currency': row['currency']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_ = transactions[transactions['target'] == susp_node]\n",
    "\n",
    "if susp_node in target_ids:\n",
    "    susp_in = True\n",
    "    \n",
    "    data['type'] = 'Time Pattern Outflow + Inflow'\n",
    "\n",
    "    idx = target_ids.index(susp_node)\n",
    "        \n",
    "    susp_index_in = list(transactions[transactions['id'].isin(groups['target']['time'][idx])].index)\n",
    "else:\n",
    "    data['type'] = 'Time Pattern Outflow'\n",
    "    susp_in = False\n",
    "\n",
    "for i in in_.index:\n",
    "    row = in_.loc[i]\n",
    "    \n",
    "    if susp_in:\n",
    "        acc = True if i in susp_index_in else False\n",
    "        if acc:\n",
    "            tag = 'accomplice'\n",
    "        else:\n",
    "            tag = 'usual'\n",
    "    else:\n",
    "        tag = 'usual'\n",
    "        \n",
    "    if row['source'] not in link_nums.keys():\n",
    "        data['nodes'].append({'id': row['source'], 'tag': tag, 'type': 'source'})  \n",
    "    \n",
    "    data['links'].append({'source': row['source'], 'target': susp_node, 'tag': tag, 'date': row['date'], 'time': row['time'], 'amount': row['amount'], 'currency': row['currency']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if id_ == 0:\n",
    "    fn = 'inout.json'\n",
    "elif id_ == 1:\n",
    "    fn = 'out.json'\n",
    "elif id_ == 2:\n",
    "    fn = 'inout2.json'\n",
    "\n",
    "with open('json/'+fn, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
